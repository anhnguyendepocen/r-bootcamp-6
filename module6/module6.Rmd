---
title: 'Module 6: Advanced Topics'
author: "Ted Laderas"
date: "July 9, 2015"
output: html_document
---

##Let's Get Advanced

This module covers the following advanced topics in R.

  1. The magic of lapply() and other apply functions
  2. The dplyr package
  3. The reshape2 package
  4. The devtools package

##Part 0: Required Packages

You will need the following packages to run this module:

```{r}
require(dplyr)
require(reshape2)
require(parallel)
require(devtools)
```

##Part 1: The Magic of lapply() and mclapply()

We've already seen that apply() can apply a function over rows and columns of a matrix. lapply() is a much more general method that operates on lists. Usually each object in the list is in an identical format.

```{r}
#Two ways of iterating over a list
data(iris)

#initialize a list with three sampled versions of iris
testList <- list(one=iris[sample(rownames(iris),30),], two=iris[sample(rownames(iris),30),], three=iris[sample(rownames(iris),30),])

#let's look at the head of each of these samples
#This is the for loop way
for(tt in testList){
  print(head(tt))
}

#the lapply way
lapply(testList, head)
```

**QUESTION 1-1**: What data structure does lapply return?

We can design a function that essentially does everything we need to do in a for loop. Note that we are taking advantage of the "..." argument to pass the cutoff argument from lapply() to the filterFrame function.

```{r}
filterFrame <- function(testFrame, cutoff){
    #filter Sepal.Width by cutoff value
    outFrame <- testFrame[testFrame$Sepal.Width > cutoff,]
    #return mean of each column
    return(colSums(outFrame[,1:4])/nrow(outFrame))
  }

testRes <- lapply(testList, filterFrame, cutoff=3.0)
testRes
```

Here's another example where we count and report the species with the largest number in each sampled frame in the list.

```{r}
countLargestSpecies<- function(testFrame){
  #count how many of each species exists in the data frame
  tab <- table(testFrame$Species)
  #find maximum number
  maxT <- max(tab)
  #return the species with the largest number in the table
  return(tab[tab == maxT])
}

lapply(testList, countLargestSpecies)
```

Another way to invoke lapply() is to use an anonymous function. An anonymous function is just an unnamed function that we supply to lapply whose first argument corresponds to the list element we are working on. So, we could do something identical to the previous code block as follows.

I try not to do this if the function is more than 2 or 3 lines, because it's not very readable. But I'm showing it to you just in case you come across it in R-code so you will not be confused.

```{r}
lapply(testList, function(testFrame){tab <- table(testFrame$Species)
                                     maxT <- max(tab)
                                     return(tab[tab == maxT])
                                     }
       )
```

We can do lapply() operations on a single data frame or matrix by operating on the column names or the row names:

```{r}

```

Similarly, if we have two or more lists that have identical names, we can do operations on both of them by operating on the list names rather than the lists themselves.

```{r}

```

By now, you should see that most everything you do in a for loop, you can do with an lapply() call.

```{r}

```

Once we have operated on these, our results are returned in a list. If the result is a single scalar, we can use unlist() to return results as a vector.

```{r}

```

Another operation that is really useful on list results is do.call(). For example, if do.call returns a row vector, we can bind our results into a matrix by using do.call("rbind", listRes):

```{r}
testMat <- do.call("rbind", testRes)
testMat
```

Why do we care about this? The first reason is that lapply() is inherently faster than for loops in general. However, the other reason is clarity. By writing a function, it is clear what we are doing over the list compared to a for loop. Much of the overhead of writing the for loop (incrementing counters, etc) is also simplified when we use lapply().

Another reason is a related function known as mclapply(), which lets us spread the work over multiple cores. Once you have an lapply statement, it is easy to convert it into an mclapply statement.

```{r}
library(parallel)
outResult <- mclapply(testList, filterFrame, mc.cores=2)
```

###Resources

For much more information about lapply and other functionals, check out this Hadley Wickham page: [http://adv-r.had.co.nz/Functionals.html](http://adv-r.had.co.nz/Functionals.html).

##Part 2: The dplyr package

[Based in part on Justin Markham's dplyr Tutorial](https://github.com/justmarkham/dplyr-tutorial)

In module 2, we learned the basics of indexing and subsetting in R. Now let's examine another way to do it with the dplyr package. If you are familiar with Unix, you may know that you can build workflows with the "|" (pipe command), taking the output of one command and routing (or piping) it into the input of another command. 

The dplyr package takes advantage of something similar, which is the magrittr pipe "%>%" to pipe the output of one function into another. You can construct many kinds of queries possible in SQL, but in a format-agnostic way (the tables can be in a database or in memory). 

We use the "%>%" to pipe a data.frame from one dplyr operation to another. These operations are known as 

- select() 
- mutate() 
- transmute()
- summarize()
- group_by()
- count()
- rename()
- slice()
- and collapse() 

The advantages to dplyr code is that it is fast and much easier to understand than standard subsetting operations, especially with lots of boolean operations. Additionally, our source data doesn't need to be a data.frame that's in memory; it can be the result of a database call, which can be great when polling dynamic data sources.

###data_frame versus data.frame

data_frame() is an extension of data.frame(), with some prettification. here

```{r}

```

###select()

The select() function allows us to pull specific columns from our data.

```{r}

```

###mutate() and transmute()

The mutate() function allows us to calculate new columns based on old functions. For example, we may want to summarize 

```{r}

```

The transmute function is 

###filter()

filter() is how we subset in dplyr. 

###Combining functions together

As you might guess, the strength of using dplyr is when we combine commands together.

###Task: Construct a query of the iris dataset that calculates a new column "PSWaverage" that averages the petal widths and sepal widths and then filters the dataset, returning only those rows with a PSWaverage > 1.8 

```{r}
library(dplyr)
data(iris)

iris %>% mutate(PSWaverage = (Petal.Width + Sepal.Width)/2) %>% filter(PSWaverage > 1.8)
```

###Task: Calculate the average Sepal Width for each iris species for those samples that have a Sepal.Length > 5.2

```{r}
library(dplyr)
data(iris)

iris %>% filter(Sepal.Length > 5.2) %>% group_by(Species) %>% summarise(mean=mean(Sepal.Width), count=n())
```

###Task: 

##Part 3: The reshape2 package

Data transformation is a necessary pain. We've already seen ways to subset and transform data using dplyr, but what about formats that are friendly to packages such as ggplot2 and ggvis? These packages require tidy data, where each row in the table corresponds to a data point. If we have data in an expression matrix (where each column are the results of a different sample), it's necessary to transform the matrix into a tidy one, where each row corresponds to a single entry in the expression matrix.

This is what the reshape2 package is all about. The main functions in reshape2 are melt and the various cast functions.

We need to "melt" the data frame to make it easier for ggplot to work with. Our melted data frame will have one data point for row, and additional Gene and Sample Columns.  First we load our data in.


```{r}
library(reshape2)
expData <- data.frame( 
  Gene = c("G1","G2","G3","G4", "G5", "G6", "G7", "G8"),
  Tumor1 = c( 5.6, 6.2, 5.6, 6.6, 1.3, 1.4, 2.1, 2.3),
  Tumor2 = c(5.4, 6.1, 5.8, 6.2, 1.3, 1.8, 2.2, 2.1),
  Normal1 = c(2.0, 2.5, 1.1, 2.8, 5.5, 5.8, 6.1, 5.7),
  Normal2 = c(2.1, 2.6, 1.3, 2.4, 5.7, 5.4, 5.8, 5.9)
)
expData
```

### Melting the data into longform data

Then we melt the data using the melt() function:

```{r}
expDataMelt <- melt(expData, id.vars="Gene", variable.name="Sample",
                    value.name = "value")
expDataMelt
```

```

##Part 4: The devtools package

The devtools package lets you do a number of useful things. The first is being able to install packages directly from GitHub. This is really useful when you need the bleeding-edge latest release of a package and the user hasn't submitted to Bioconductor or CRAN.

```{r}
install_github("laderast/Consense")
```

